{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fasttext import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "import string\n",
    "from typing import List, Optional\n",
    "from conlleval import evaluate\n",
    "from fastai.callbacks.tracker import EarlyStoppingCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PAD, UNK, NUM, PUNCT = '<PAD>', '<UNK>', '<NUM>', '<PUNCT>'\n",
    "CHARACTERS = '‘ẹjO:òồọðỡụẽÂưiŨdỜ”ẦVMẩCệ“+v!ỹỉPt2/lứỄỐƠúằíỔẢắDqữ?SJỳẳấwƯ*ẫQơ3éeĩTÔuỲbâựỰÐể0ùừWợBô²èá4êỷÍỖRL,ộ9ynf%g~³¼ẤỗHIG6Ệử°Yậổx(Ởra&Ẩẵễóở)Đm>Áềẻ;sàỮõẬăỵủkỦì]_Ạ7–ÕNãịố8hỪ…\\'[Eớ.ạũếXĂờUỒÝỨảpÀầặ1đcýÚ’zÊỏẶoKZ5\"FA-'\n",
    "TAGS = ['B-MISC', 'I-MISC', 'B-PER', 'O', 'B-LOC', 'I-PER', 'B-ORG', 'I-ORG', 'I-LOC']\n",
    "POSES = ['R', 'Nc', 'Vy', 'M', 'A', 'Z', 'N', 'CH', 'Ny', 'Nu', 'C', 'V', 'L', 'I', 'P', 'Np', 'T', 'FW', 'X', 'E']\n",
    "CHUNKS = ['B-VP', 'B-AP', 'B-PP', 'I-AP', 'B-NP', 'O', 'I-VP', 'I-NP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_vocab_embedding(type: str, path):\n",
    "    def load_pretrained_embedding_from_fasttext_cc_model(path):\n",
    "        model = FastText.load_model(path)\n",
    "\n",
    "        embedding_dim = model.get_dimension()\n",
    "        words = [UNK, PAD, *model.words, NUM, PUNCT]\n",
    "        vocab = Vocab(words)\n",
    "        embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.cat([\n",
    "                (torch.rand(1, embedding_dim,dtype=torch.float)\n",
    "                 .uniform_(- math.sqrt(3 / embedding_dim),math.sqrt(3 / embedding_dim))),\n",
    "                torch.zeros(1, embedding_dim,dtype=torch.float),\n",
    "                torch.tensor(model.get_input_matrix()),\n",
    "                (torch.rand(2, embedding_dim,dtype=torch.float)\n",
    "                 .uniform_(- math.sqrt(3 / embedding_dim),math.sqrt(3 / embedding_dim)))       \n",
    "            ]),\n",
    "            padding_idx=vocab.stoi[PAD]\n",
    "        )\n",
    "        return vocab, embeddings\n",
    "            \n",
    "\n",
    "    def load_pretrained_embedding_from_gensim_fasttext_model(path):\n",
    "        model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "        embedding_dim = model.vector_size\n",
    "        words = [UNK, PAD, *model.index2word, NUM, PUNCT]\n",
    "        vocab = Vocab(words)\n",
    "        embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.cat([\n",
    "                (torch.rand(1, embedding_dim, dtype=torch.float)\n",
    "                                 .uniform_(- math.sqrt(3 / embedding_dim),math.sqrt(3 / embedding_dim))),\n",
    "                torch.zeros(1, embedding_dim, dtype=torch.float)\n",
    "                torch.tensor(model.vectors),\n",
    "                (torch.rand(2, embedding_dim, dtype=torch.float)\n",
    "                 .uniform_(- math.sqrt(3 / embedding_dim),math.sqrt(3 / embedding_dim)))\n",
    "            ]),\n",
    "            padding_idx=vocab.stoi[PAD]\n",
    "        )\n",
    "        return vocab, embeddings\n",
    "    \n",
    "    assert type in ['fasttext_cc', 'fasttext_gensim']\n",
    "    if type == 'fasttext_cc':\n",
    "        return load_pretrained_embedding_from_fasttext_cc_model(path)\n",
    "    else:\n",
    "        return load_pretrained_embedding_from_gensim_fasttext_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WordVocab(Vocab):\n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        return [self.stoi[self.process_word(w)] for w in t]\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_word(word: str, lowercase=True):\n",
    "        if lowercase:\n",
    "            word = word.lower()\n",
    "        if word[0].isdigit():\n",
    "            return NUM\n",
    "        if word[0] in string.punctuation:\n",
    "            return PUNCT\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "character_vocab = WordVocab([UNK, PAD, *CHARACTERS])\n",
    "pos_vocab = Vocab([PAD, *POSES])\n",
    "chunk_vocab = Vocab([PAD, *CHUNKS])\n",
    "# tag_vocab = Vocab([*TAGS, PAD])\n",
    "tag_vocab = Vocab(TAGS)\n",
    "word_vocab, emb = load_pretrained_vocab_embedding(\n",
    "    type='fasttext_cc',\n",
    "    path='data/pretrained_embedding/fasttext_pretrained_embeddings_300.bin'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(fn):\n",
    "    sentences = []\n",
    "    tag_sentences = []\n",
    "    sentence = []\n",
    "    tag_sentence = []\n",
    "    with open(fn, mode='r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line:\n",
    "                tokens = line.split()\n",
    "                if len(tokens) == 4:\n",
    "                    sentence.append(tuple(tokens[:3]))\n",
    "                    tag_sentence.append(tokens[-1])\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "                tag_sentences.append(tag_sentence)\n",
    "                sentence = []\n",
    "                tag_sentence = []\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            tag_sentences.append(tag_sentence)\n",
    "        f.close()\n",
    "    \n",
    "    return sentences, tag_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_sentences, train_tags = read_data('data/data/train.txt')\n",
    "dev_sentences, dev_tags = read_data('data/data/dev.txt')\n",
    "test_sentences, test_tags = read_data('data/data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TagPreProcessor(PreProcessor):\n",
    "    def __init__(\n",
    "            self,\n",
    "            tag_vocab: Vocab\n",
    "    ):\n",
    "        super(TagPreProcessor, self).__init__()\n",
    "        self.tag_vocab = tag_vocab\n",
    "\n",
    "    def process_one(self, tag:Any):\n",
    "        return self.tag_vocab.numericalize(tag)\n",
    "    \n",
    "\n",
    "class SentencePreProcessor(PreProcessor):\n",
    "    def __init__(\n",
    "            self, \n",
    "            character_vocab: Vocab, \n",
    "            pos_vocab: Vocab, \n",
    "            chunk_vocab: Vocab, \n",
    "            # tag_vocab: Vocab,\n",
    "            word_vocab: Vocab,\n",
    "            ds: Collection=None\n",
    "    ):\n",
    "        super(SentencePreProcessor, self).__init__(ds=ds)\n",
    "        self.character_vocab = character_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.chunk_vocab = chunk_vocab\n",
    "        # self.tag_vocab = tag_vocab\n",
    "        self.word_vocab = word_vocab\n",
    "    \n",
    "    def process_one(self, sentence:Any):\n",
    "        words, poses, chunks = zip(*sentence)\n",
    "        \n",
    "        word_indices = self.word_vocab.numericalize([word.lower() for word in words])\n",
    "        pos_indices = self.pos_vocab.numericalize(poses)\n",
    "        chunk_indices = self.chunk_vocab.numericalize(chunks)\n",
    "        # tag_indices = self.tag_vocab.numericalize(tags)\n",
    "        character_indices = [\n",
    "            self.character_vocab.numericalize(word) for word in words\n",
    "        ]\n",
    "        \n",
    "        return word_indices, character_indices, pos_indices, chunk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence_processor = SentencePreProcessor(\n",
    "    character_vocab=character_vocab,\n",
    "    pos_vocab=pos_vocab,\n",
    "    chunk_vocab=chunk_vocab,\n",
    "    # tag_vocab=tag_vocab,\n",
    "    word_vocab=word_vocab\n",
    ")\n",
    "\n",
    "train_il = ItemList(\n",
    "    items=train_sentences,\n",
    "    processor=sentence_processor,\n",
    ").process()\n",
    "\n",
    "dev_il = ItemList(\n",
    "    items=dev_sentences,\n",
    "    processor=sentence_processor\n",
    ").process()\n",
    "\n",
    "test_il = ItemList(\n",
    "    items=test_sentences,\n",
    "    processor=sentence_processor\n",
    ").process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tag_processor = TagPreProcessor(tag_vocab=tag_vocab)\n",
    "train_tl = ItemList(\n",
    "    items=train_tags,\n",
    "    processor=tag_processor,\n",
    ").process()\n",
    "\n",
    "dev_tl = ItemList(\n",
    "    items=dev_tags,\n",
    "    processor=tag_processor,\n",
    ").process()\n",
    "\n",
    "test_tl = ItemList(\n",
    "    items=test_tags,\n",
    "    processor=tag_processor,\n",
    ").process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test_tl[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ll = LabelList(x=train_il, y=train_tl)\n",
    "dev_ll = LabelList(x=dev_il, y=dev_tl)\n",
    "test_ll = LabelList(x=test_il, y=test_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def pad_collate(samples, pad_idx=1, pad_first=False):\n",
    "#     max_len = max([len(s[0]) for s in samples])\n",
    "#     res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "#     for i,s in enumerate(samples):\n",
    "#         if pad_first: res[i, -len(s[0]):] = LongTensor(s[0])\n",
    "#         else:         res[i, :len(s[0]) ] = LongTensor(s[0])\n",
    "#     return res, tensor([s[1] for s in samples])\n",
    "# \n",
    "# def padding_collate(samples, pad_idx=1, pad_first=False, sort=False):\n",
    "#     lengths = [len(s) for s in samples]\n",
    "#     max_len = max(lengths)\n",
    "#     res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "#     for i,s in enumerate(samples):\n",
    "#         if pad_first: res[i, -len(s):] = LongTensor(s)\n",
    "#         else:         res[i, :len(s) ] = LongTensor(s)\n",
    "# \n",
    "#     if sort:\n",
    "#         args_sort = torch.tensor(lengths, dtype=torch.long).argsort(descending=True)\n",
    "#         return res[args_sort], torch.argsort(args_sort)\n",
    "#     return res\n",
    "# \n",
    "# \n",
    "# def collate_fn(batch_data, word_bs=64, pad_first=False):\n",
    "#     batch_data = sorted(batch_data, key=lambda x: len(x[0][0]), reverse=True)\n",
    "#     xs, ys = zip(*batch_data)\n",
    "# \n",
    "#     sentences, characters, poses, chunks = zip(*xs)\n",
    "#     words = sum(characters, [])\n",
    "# \n",
    "#     # pad sentences, poses, chunks \n",
    "#     pad_sentences, pad_poses, pad_chunks = padding_collate(sentences), padding_collate(poses), padding_collate(chunks)\n",
    "# \n",
    "#     # pad characters\n",
    "#     num_words = torch.tensor([len(sentence) for sentence in sentences]).long()\n",
    "#     num_word_batch = (len(words) - 1) // word_bs + 1\n",
    "# \n",
    "#     pad_word_batches = [\n",
    "#         padding_collate(words[i * word_bs: (i + 1) * word_bs], sort=True) for i in range(num_word_batch)\n",
    "#     ]\n",
    "# \n",
    "#     # pad ys\n",
    "#     pad_tags = padding_collate(ys)\n",
    "# \n",
    "#     return (pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words), pad_tags\n",
    "\n",
    "class CollateFn:\n",
    "    def __init__(\n",
    "            self,\n",
    "            word_vocab: Vocab,\n",
    "            character_vocab: Vocab,\n",
    "            pos_vocab: Vocab,\n",
    "            chunk_vocab: Vocab,\n",
    "            tag_vocab: Vocab,\n",
    "            word_bs=64,\n",
    "            pad_first=False\n",
    "    ):\n",
    "        self.word_vocab = word_vocab\n",
    "        self.character_vocab = character_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.chunk_vocab = chunk_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.word_bs = word_bs\n",
    "        self.pad_first = pad_first\n",
    "        \n",
    "        self.word_pad_idx = self.word_vocab.stoi[PAD]\n",
    "        self.character_pad_idx = self.character_vocab.stoi[PAD]\n",
    "        self.pos_pad_idx = self.pos_vocab.stoi[PAD]\n",
    "        self.chunk_pad_idx = self.chunk_vocab.stoi[PAD]\n",
    "        self.tag_pad_idx = self.tag_vocab.stoi[PAD]\n",
    "    \n",
    "    @staticmethod\n",
    "    def padding_collate(samples, pad_idx=1, pad_first=False, sort=False):\n",
    "        lengths = [len(s) for s in samples]\n",
    "        max_len = max(lengths)\n",
    "        res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "        for i,s in enumerate(samples):\n",
    "            if pad_first: res[i, -len(s):] = LongTensor(s)\n",
    "            else:         res[i, :len(s) ] = LongTensor(s)\n",
    "        \n",
    "        if sort:\n",
    "            args_sort = torch.tensor(lengths, dtype=torch.long).argsort(descending=True)\n",
    "            return res[args_sort], torch.argsort(args_sort)\n",
    "        return res\n",
    "    \n",
    "    def __call__(self, batch_data):\n",
    "        batch_data = sorted(batch_data, key=lambda x: len(x[0][0]), reverse=True)\n",
    "        xs, ys = zip(*batch_data)\n",
    "        \n",
    "        sentences, characters, poses, chunks = zip(*xs)\n",
    "        words = sum(characters, [])\n",
    "       \n",
    "        # pad sentences, poses, chunks \n",
    "        pad_sentences, pad_poses, pad_chunks = (\n",
    "            self.padding_collate(sentences, pad_idx=self.word_pad_idx, pad_first=self.pad_first), \n",
    "            self.padding_collate(poses, pad_idx=self.pos_pad_idx, pad_first=self.pad_first), \n",
    "            self.padding_collate(chunks, pad_idx=self.chunk_pad_idx, pad_first=self.pad_first)\n",
    "        )\n",
    "        \n",
    "        # pad characters\n",
    "        num_words = torch.tensor([len(sentence) for sentence in sentences]).long()\n",
    "        num_word_batch = (len(words) - 1) // self.word_bs + 1\n",
    "        \n",
    "        pad_word_batches = [\n",
    "            self.padding_collate(\n",
    "                words[i * self.word_bs: (i + 1) * self.word_bs], \n",
    "                pad_idx=self.character_pad_idx,\n",
    "                pad_first=self.pad_first,\n",
    "                sort=True\n",
    "            ) for i in range(num_word_batch)\n",
    "        ]\n",
    "        \n",
    "        # pad ys\n",
    "        pad_tags = self.padding_collate(ys, pad_idx=self.tag_pad_idx, pad_first=self.pad_first)\n",
    "        \n",
    "        return (pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words), pad_tags\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "databunch = DataBunch.create(\n",
    "    train_ds=train_ll,\n",
    "    valid_ds=dev_ll,\n",
    "    test_ds=test_ll,\n",
    "    collate_fn=CollateFn(word_vocab, character_vocab, pos_vocab, chunk_vocab,tag_vocab, 64, False),\n",
    "    bs=8,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words), pad_tags = databunch.one_batch()\n",
    "\n",
    "# pad_word_batch, recover_indices = pad_word_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(pad_word_batch, recover_indices)\n",
    "# bs, sl = pad_word_batch.size()\n",
    "# mask = pad_word_batch == 1\n",
    "# lengths = sl - (mask.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embedding = nn.Embedding(num_embeddings=len(character_vocab.stoi), embedding_dim=50, padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embs = embedding(pad_word_batch.T)\n",
    "# embs.size(), nn.utils.rnn.pack_padded_sequence(embs, lengths=lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CharacterLSTM(nn.Module):\n",
    "    def __init__(self, vocab: Vocab, embedding_dim, hidden_dim):\n",
    "        super(CharacterLSTM, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.pad_idx = self.vocab.stoi['<PAD>']\n",
    "        \n",
    "        self.embedding = self._init_embedding(\n",
    "            num_embeddings=len(vocab.itos),\n",
    "            embedding_dim=embedding_dim,\n",
    "            pad_idx=self.pad_idx\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def _trunc_normal_(x: torch.Tensor, mean: float = 0., std: float = 1.) -> torch.Tensor:\n",
    "        \"\"\"Truncated normal initialization.\"\"\"\n",
    "        # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n",
    "        return x.normal_().fmod_(2).mul_(std).add_(mean)\n",
    "    \n",
    "    def _init_embedding(self, num_embeddings: int, embedding_dim: int, pad_idx=0) -> nn.Module:\n",
    "        \"\"\"Create an embedding layer.\"\"\"\n",
    "        emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=pad_idx)\n",
    "        # See https://arxiv.org/abs/1711.09160\n",
    "        with torch.no_grad(): self._trunc_normal_(emb.weight, std=0.01)\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, *input: Any, **kwargs: Any):\n",
    "        pad_word_batches, num_words = input\n",
    "        max_num_words = num_words.max().item()\n",
    "        \n",
    "        batch_outputs = []\n",
    "        for pad_word_batch, recover_indices in pad_word_batches:\n",
    "            batch_outputs.append(self.forward_one(pad_word_batch, recover_indices))\n",
    "        \n",
    "        outputs = torch.cat(batch_outputs, dim=0).split_with_sizes(num_words.tolist())\n",
    "        outputs = [\n",
    "            nn.functional.pad(\n",
    "                output, pad=[0, 0, 0, max_num_words - output.size(0)], \n",
    "                mode='constant', value=0) \n",
    "            for output in outputs\n",
    "        ]\n",
    "        \n",
    "        return torch.stack(outputs)\n",
    "            \n",
    "    \n",
    "    def forward_one(self, pad_word_batch, recover_indices):\n",
    "        bs, sl = pad_word_batch.size()\n",
    "        mask = pad_word_batch == 1\n",
    "        lengths = sl - mask.sum(1)\n",
    "        embs = self.embedding(pad_word_batch)\n",
    "        embs_packed = nn.utils.rnn.pack_padded_sequence(embs, lengths=lengths, batch_first=True)\n",
    "        outputs, _ = self.lstm(embs_packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = torch.cat([\n",
    "            outputs[0, :, :self.hidden_dim],\n",
    "            outputs[lengths - 1, range(lengths.size(0)), self.hidden_dim:]\n",
    "        ], dim=1)\n",
    "        \n",
    "        return outputs[recover_indices]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%        \n"
    }
   },
   "outputs": [],
   "source": [
    "class ContextLSTM(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            word_vocab: Vocab,\n",
    "            word_embedding_dim,\n",
    "            context_hidden_dim,\n",
    "            pretrained_word_embedding: nn.Embedding,\n",
    "            character_vocab: Vocab,\n",
    "            character_embedding_dim,\n",
    "            character_hidden_dim,\n",
    "            chunk_vocab: Vocab=None,\n",
    "            pos_vocab: Vocab=None,\n",
    "            use_pos_chunk=False,\n",
    "            dropout=0.\n",
    "    ):\n",
    "        super(ContextLSTM, self).__init__()\n",
    "        self.use_pos_chunk = use_pos_chunk\n",
    "        self.word_vocab = word_vocab\n",
    "        \n",
    "        self.chunk_embedding = None\n",
    "        self.pos_embedding = None\n",
    "        if use_pos_chunk:\n",
    "            assert chunk_vocab is not None, 'use_pos_chunk is True, require chunk_vocab'\n",
    "            assert pos_vocab is not None, 'use_pos_chunk is True, require pos_vocab'\n",
    "            self.chunk_embedding = self._init_one_hot_embedding(len(chunk_vocab.itos), chunk_vocab.stoi[PAD])\n",
    "            self.pos_embedding = self._init_one_hot_embedding(len(pos_vocab.itos), pos_vocab.stoi[PAD])\n",
    "            \n",
    "        if pretrained_word_embedding is not None:\n",
    "            self.word_embedding = pretrained_word_embedding\n",
    "            self.word_embedding_dim = pretrained_word_embedding.embedding_dim\n",
    "            self.num_word_embeddings = pretrained_word_embedding.num_embeddings\n",
    "        else:\n",
    "            self.word_embedding_dim = word_embedding_dim\n",
    "            self.num_word_embeddings = len(word_vocab.itos)\n",
    "            self.word_embedding = self._init_embedding(\n",
    "                num_embeddings=self.num_word_embeddings,\n",
    "                embedding_dim=word_embedding_dim,\n",
    "                pad_idx=word_vocab.stoi['<PAD>']\n",
    "            )\n",
    "            \n",
    "        \n",
    "        self.character_lstm = CharacterLSTM(\n",
    "            vocab=character_vocab,\n",
    "            embedding_dim=character_embedding_dim,\n",
    "            hidden_dim=character_hidden_dim\n",
    "        )\n",
    "        \n",
    "        context_input_dim = (self.word_embedding_dim \n",
    "                             + ((len(chunk_vocab.itos) + len(pos_vocab.itos) - 2) if use_pos_chunk else 0)\n",
    "                             + 2 * character_hidden_dim)\n",
    "        self.context_lstm = nn.LSTM(\n",
    "            input_size=context_input_dim,\n",
    "            hidden_size=context_hidden_dim,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _trunc_normal_(x: torch.Tensor, mean: float = 0., std: float = 1.) -> torch.Tensor:\n",
    "        \"\"\"Truncated normal initialization.\"\"\"\n",
    "        # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n",
    "        return x.normal_().fmod_(2).mul_(std).add_(mean)\n",
    "    \n",
    "    def _init_embedding(self, num_embeddings: int, embedding_dim: int, pad_idx=0) -> nn.Module:\n",
    "        \"\"\"Create an embedding layer.\"\"\"\n",
    "        emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=pad_idx)\n",
    "        # See https://arxiv.org/abs/1711.09160\n",
    "        with torch.no_grad(): self._trunc_normal_(emb.weight, std=0.01)\n",
    "        return emb\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_one_hot_embedding(vocab_size, pad_idx):\n",
    "        weights = torch.zeros(vocab_size - 1, vocab_size - 1)\n",
    "        weights[range(vocab_size - 1), range(vocab_size - 1)] = 1\n",
    "        weights = torch.cat([weights[:pad_idx], torch.zeros(1, vocab_size - 1), weights[pad_idx:]])\n",
    "        return nn.Embedding.from_pretrained(weights, freeze=True, padding_idx=pad_idx)\n",
    "        \n",
    "    \n",
    "    def forward(self, *input: Any, **kwargs: Any):\n",
    "        pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words = input\n",
    "        \n",
    "        # word with character level features\n",
    "        combined_features = [self.character_lstm(pad_word_batches, num_words)]\n",
    "        \n",
    "        # pos, chunk feature with one-hot encoding if use pos chunk\n",
    "        if self.use_pos_chunk:\n",
    "            combined_features.append(self.pos_embedding(pad_poses))\n",
    "            combined_features.append(self.chunk_embedding(pad_chunks))\n",
    "        \n",
    "        # word embedding features\n",
    "        combined_features.append(self.word_embedding(pad_sentences))\n",
    "        \n",
    "        combined_features = torch.cat(combined_features, dim=2)\n",
    "        \n",
    "        # dropout\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        \n",
    "        bs, ls = pad_sentences.size()\n",
    "        mask = pad_sentences == self.word_vocab.stoi[PAD]\n",
    "        lengths = ls - mask.sum(1)\n",
    "        \n",
    "        packed_combine_features = nn.utils.rnn.pack_padded_sequence(\n",
    "            combined_features,\n",
    "            lengths=lengths,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        packed_outputs, _ = self.context_lstm(packed_combine_features)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        # dropout\n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# context_lstm = ContextLSTM(\n",
    "#     word_vocab=word_vocab,\n",
    "#     word_embedding_dim=300,\n",
    "#     context_hidden_dim=150,\n",
    "#     pretrained_word_embedding=emb,\n",
    "#     character_vocab=character_vocab,\n",
    "#     character_embedding_dim=100,\n",
    "#     character_hidden_dim=100,\n",
    "#     chunk_vocab=chunk_vocab,\n",
    "#     pos_vocab=pos_vocab,\n",
    "#     use_pos_chunk=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# context_lstm(pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BiLstmCrf(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            word_vocab: Vocab,\n",
    "            word_embedding_dim: int,\n",
    "            context_hidden_dim: int,\n",
    "            pretrained_word_embedding: nn.Embedding,\n",
    "            character_vocab: Vocab,\n",
    "            character_embedding_dim: int,\n",
    "            character_hidden_dim: int,\n",
    "            tag_vocab: Vocab,\n",
    "            chunk_vocab=None,\n",
    "            pos_vocab=None,\n",
    "            use_pos_chunk=False,\n",
    "            dropout=0.35\n",
    "    ):\n",
    "        super(BiLstmCrf, self).__init__()\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.word_vocab = word_vocab\n",
    "        self.use_pos_chunk = use_pos_chunk\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.context_lstm = ContextLSTM(\n",
    "            word_vocab=word_vocab,\n",
    "            word_embedding_dim=word_embedding_dim,\n",
    "            context_hidden_dim=context_hidden_dim,\n",
    "            pretrained_word_embedding=pretrained_word_embedding,\n",
    "            character_vocab=character_vocab,\n",
    "            character_embedding_dim=character_embedding_dim,\n",
    "            character_hidden_dim=character_hidden_dim,\n",
    "            chunk_vocab=chunk_vocab,\n",
    "            pos_vocab=pos_vocab,\n",
    "            use_pos_chunk=use_pos_chunk,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # self.hidden2tag = nn.Linear(2 * context_hidden_dim, len(tag_vocab.itos))\n",
    "        self.hidden2tag = self.get_linear_layer(2 * context_hidden_dim, len(tag_vocab.itos))\n",
    "        self.crf = CRF(\n",
    "            num_tags=len(tag_vocab.itos),\n",
    "            # batch_first=True\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_linear_layer(input_dim, output_dim):\n",
    "        linear_layer = nn.Linear(input_dim, output_dim, bias=True)\n",
    "        mean = 0.0  # std_dev = np.sqrt(variance)\n",
    "        std_dev = np.sqrt(2 / (output_dim + input_dim))  # np.sqrt(1 / m) # np.sqrt(1 / n)\n",
    "        weight = np.random.normal(mean, std_dev, size=(output_dim, input_dim)).astype(np.float32)\n",
    "        std_dev = np.sqrt(1 / output_dim)  # np.sqrt(2 / (m + 1))\n",
    "        bt = np.random.normal(mean, std_dev, size=output_dim).astype(np.float32)\n",
    "\n",
    "        linear_layer.weight.data = torch.tensor(weight, requires_grad=True)\n",
    "        linear_layer.bias.data = torch.tensor(bt, requires_grad=True)\n",
    "        return linear_layer\n",
    "    \n",
    "    def forward(self, *input: Any, **kwargs: Any):\n",
    "        pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words = input\n",
    "        emissions = self.hidden2tag(self.context_lstm(pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words))\n",
    "        mask = pad_sentences != self.word_vocab.stoi[PAD]\n",
    "        \n",
    "        if self.training:\n",
    "            return emissions, mask\n",
    "        else:\n",
    "            return emissions, mask, self.crf.decode(emissions, mask.transpose(0, 1))\n",
    "    \n",
    "    def get_loss_func(self, reduction='token_mean'):\n",
    "        def loss_func(output, tags):\n",
    "            if len(output) == 2:\n",
    "                emissions, mask = output\n",
    "            else:\n",
    "                emissions, mask, _ = output\n",
    "            return - self.crf(\n",
    "                emissions,\n",
    "                tags.transpose(0, 1),\n",
    "                mask.transpose(0, 1),\n",
    "                reduction\n",
    "            )\n",
    "        return loss_func\n",
    "    \n",
    "    def predict(self, *input: Any, **kwargs: Any):\n",
    "        pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words = input\n",
    "        emissions = self.hidden2tag(self.context_lstm(pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words))\n",
    "        mask = pad_sentences != self.word_vocab.stoi[PAD]\n",
    "        return self.crf.decode(emissions, mask.transpose(0, 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = BiLstmCrf(\n",
    "    word_vocab=word_vocab,\n",
    "    word_embedding_dim=300,\n",
    "    context_hidden_dim=150,\n",
    "    pretrained_word_embedding=emb,\n",
    "    character_vocab=character_vocab,\n",
    "    character_embedding_dim=100,\n",
    "    character_hidden_dim=100,\n",
    "    tag_vocab=tag_vocab,\n",
    "    chunk_vocab=chunk_vocab,\n",
    "    pos_vocab=pos_vocab,\n",
    "    use_pos_chunk=True\n",
    ")\n",
    "\n",
    "model=model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model.crf.start_transitions, model.crf.transitions, model.crf.end_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = model.get_loss_func(reduction=\"token_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words), pad_tags\n",
    "# output = model(pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words)\n",
    "# loss_func(output, pad_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# output = model(pad_sentences, pad_poses, pad_chunks, *pad_word_batches, num_words)\n",
    "# output, pad_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ConllevalMetric(LearnerCallback):\n",
    "    _order=-20\n",
    "    def __init__(self, learn, func, tag_vocab):\n",
    "        super().__init__(learn)\n",
    "        self.func = func\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.y_true, self.y_pred = None, None\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.learn.recorder.add_metric_names(['precision', 'recall', 'f1-score'])\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs:Any) ->None:\n",
    "        self.y_true, self.y_pred = [], []\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, **kwargs) ->None:\n",
    "        if type(last_output) == tuple:\n",
    "            emissions, mask = last_output\n",
    "            last_output = self.learn.model.crf.decode(emissions, mask.transpose(0, 1))\n",
    "        for output, target in zip(last_output, last_target):\n",
    "            self.y_true.extend([self.tag_vocab.itos[i] for i in target.tolist()[:len(output)]])\n",
    "            self.y_pred.extend([self.tag_vocab.itos[i] for i in output])\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs:Any) ->None:\n",
    "        return add_metrics(last_metrics, self.func(self.y_true, self.y_pred, verbose=False))\n",
    "        \n",
    "\n",
    "class F1Score(Callback):\n",
    "    def __init__(self, func, tag_vocab):\n",
    "        self.func, self.name, self.tag_vocab = func, 'f1_score', tag_vocab\n",
    "        self.y_true, self.y_pred = None, None\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.y_true, self.y_pred = [], []\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        _, _, last_output = last_output\n",
    "        for output, target in zip(last_output, last_target):\n",
    "            self.y_true.extend([self.tag_vocab.itos[i] for i in target.tolist()[:len(output)]])\n",
    "            self.y_pred.extend([self.tag_vocab.itos[i] for i in output])\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs:Any) ->None:\n",
    "        return add_metrics(last_metrics, self.func(self.y_true, self.y_pred, verbose=False)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "learner = Learner(\n",
    "    data=databunch, \n",
    "    model=model, \n",
    "    loss_func=loss_func,\n",
    "    path='.'\n",
    ")\n",
    "\n",
    "conlleval_metric = ConllevalMetric(learner, partial(evaluate, verbose=False), tag_vocab)\n",
    "f1score = F1Score(func=partial(evaluate, verbose=False), tag_vocab=tag_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "learner.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-28015fb789de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mSaveModelCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1-score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'improvement'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mEarlyStoppingCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mconlleval_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-774d2c3329c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mpad_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpad_word_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0memissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpad_word_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sentences\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-7a856e08367b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         )\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mpacked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_combine_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_packed\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n\u001b[0;32m--> 529\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# learner.fit(5, lr=0.01, callbacks=[conlleval_metric])\n",
    "learner.fit_one_cycle(30, 3e-2,\n",
    "                      metrics=[f1score],\n",
    "                      callbacks=[\n",
    "                          SaveModelCallback(learner, monitor='f1-score', every='improvement', name='best_model'),\n",
    "                          EarlyStoppingCallback(learner, monitor='valid_loss', min_delta=0.01, patience=10),\n",
    "                          # conlleval_metric\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# learner.save('model_1', return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Learner(data=DataBunch;\n\nTrain: LabelList (14861 items)\nx: ItemList\n[list([29, 8, 68, 113, 207, 1161, 85, 24, 58, 40, 0, 238, 7323, 2, 1081, 33, 804, 6533, 3174, 7041, 7, 209, 2, 29, 8, 0, 108, 85, 40, 394, 238, 193, 18, 0, 953, 13693, 2844, 160, 30, 214])\n list([[182, 126], [37, 137], [183, 191, 98], [182, 15, 171, 98, 101], [71, 16, 76, 98], [98, 101, 47, 98], [98, 158, 56, 34], [182, 76], [182, 16], [34, 79], [56, 98, 0, 182, 95, 0, 18, 15, 62, 98, 101], [136, 121, 98, 101], [34, 158, 86, 16, 0, 71, 146, 98, 158, 0, 18, 15, 62, 98, 101], [0], [183, 158, 16, 168, 130], [182, 168, 98], [37, 15, 81, 98, 101], [158, 137, 98, 101, 0, 158, 191, 86], [37, 15, 69, 0, 34, 158, 83, 98, 101], [182, 15, 171, 98, 101, 0, 71, 16, 76, 98], [183, 143, 121], [34, 158, 168, 0, 101, 16, 164, 16], [0], [182, 126], [37, 137], [158, 176, 16, 0, 34, 120, 146, 98, 158], [37, 164, 98], [98, 158, 56, 34], [34, 79], [34, 72, 97], [136, 121, 98, 101], [182, 83, 98, 101], [29, 164, 16], [0, 0, 0, 0, 0, 0], [37, 15, 81, 34], [34, 137, 69, 0, 71, 85], [49, 69, 121, 0, 37, 166, 16], [130, 106, 16], [98, 141, 130], [0, 0, 0]])\n list([15, 12, 2, 7, 7, 5, 5, 20, 12, 20, 16, 12, 16, 8, 12, 20, 7, 7, 12, 7, 20, 7, 8, 15, 12, 7, 5, 1, 20, 7, 12, 7, 20, 4, 2, 7, 12, 13, 7, 8])\n list([5, 1, 5, 5, 5, 2, 2, 3, 1, 3, 5, 1, 5, 6, 1, 3, 5, 5, 1, 5, 3, 5, 6, 5, 1, 5, 2, 6, 3, 5, 1, 5, 3, 5, 5, 5, 1, 5, 5, 6])],[list([12, 401, 0, 1525, 125, 84, 1096, 2, 988, 2, 1154, 261, 14, 1482, 5587, 234, 2, 24, 1784, 122, 69, 15, 10057, 174, 20051, 19, 1784, 160, 21, 381, 1331, 74, 46, 7943, 3778, 15034, 651, 214])\n list([[130, 95, 34], [183, 158, 69, 97, 168, 98], [158, 176, 16, 0, 34, 120, 146, 98, 158], [117, 69, 97, 88, 98], [71, 121], [98, 15, 164, 183], [130, 121, 37, 121, 97, 136, 16, 121], [0], [136, 16, 98, 101, 121, 177, 191, 120, 65], [0], [16, 98, 18, 191, 98, 65, 136, 16, 121], [29, 79, 121], [182, 15, 81, 183], [177, 158, 126, 98, 101, 0, 29, 16, 88, 98], [34, 69, 116, 16, 0, 34, 120, 134], [34, 158, 73, 183, 0, 158, 16, 26, 98], [0], [182, 76], [183, 176, 130, 0, 98, 158, 115, 98], [182, 16, 133, 69], [130, 137], [183, 86, 183], [34, 158, 69, 89, 0, 34, 158, 143], [34, 137, 69], [29, 16, 125, 98, 0, 18, 15, 62, 98, 101], [182, 154], [183, 176, 130, 0, 98, 158, 115, 98], [130, 106, 16], [144, 158, 16], [98, 101, 158, 65], [98, 158, 47, 183], [34, 164, 16], [0], [158, 176, 16, 0, 34, 180, 183], [65, 191, 0, 71, 16, 76, 98], [130, 121, 37, 121, 183, 183, 121], [0], [0, 0, 0]])\n list([4, 7, 7, 12, 4, 7, 16, 8, 16, 8, 16, 1, 12, 7, 16, 12, 8, 20, 12, 7, 11, 13, 7, 7, 5, 1, 12, 13, 7, 12, 12, 1, 8, 7, 7, 16, 8, 8])\n list([5, 5, 5, 1, 5, 5, 5, 6, 5, 6, 5, 6, 1, 5, 5, 1, 6, 3, 1, 5, 6, 5, 5, 5, 2, 6, 1, 5, 5, 1, 1, 6, 6, 5, 5, 8, 6, 6])],[list([40, 545, 404, 7, 40157, 214])\n list([[34, 79], [71, 38, 183], [182, 16, 26, 98], [183, 143, 121], [16, 130, 71], [0, 0, 0]])\n list([20, 2, 7, 20, 9, 8]) list([3, 5, 5, 3, 5, 6])],[list([123, 4343, 191, 21, 137, 14, 2348, 7, 3235, 5184, 34917, 28, 925, 564, 7, 196, 2400, 294, 35, 40157, 36, 37, 1096, 28, 806, 665, 123, 24, 561, 22, 258, 80, 85, 27, 7943, 3778, 15034, 3])\n list([[183, 158, 42, 98, 101, 0, 34, 83, 16], [37, 88, 98, 0, 182, 15, 171, 98, 101], [98, 101, 121, 97], [144, 158, 16], [98, 158, 115, 98], [182, 15, 81, 183], [65, 130, 121, 16, 37], [183, 143, 121], [98, 101, 137, 16], [98, 191, 65, 37], [183, 158, 191, 191, 98, 101], [0], [34, 120, 15, 127, 98, 101], [182, 166, 16, 0, 18, 16, 26, 98], [183, 143, 121], [183, 62, 0, 49, 69, 121, 98], [158, 137, 98, 101, 0, 158, 176, 16], [49, 69, 156, 183, 0, 34, 168], [0], [16, 130, 71], [0], [34, 166, 16], [130, 121, 37, 121, 97, 136, 16, 121], [0], [182, 8, 98, 101, 0, 184], [34, 16, 168, 177], [183, 158, 42, 98, 101, 0, 34, 83, 16], [182, 76], [183, 69, 98, 101, 0, 183, 56, 177], [98, 158, 50, 98, 101], [34, 158, 83, 98, 101, 0, 34, 16, 98], [130, 164, 16], [98, 158, 56, 34], [29, 133], [158, 176, 16, 0, 34, 180, 183], [65, 191, 0, 71, 16, 76, 98], [130, 121, 37, 121, 183, 183, 121], [0]])\n list([15, 12, 17, 7, 12, 1, 18, 20, 7, 16, 16, 8, 7, 7, 20, 7, 7, 7, 8, 16, 8, 20, 16, 8, 12, 12, 15, 20, 12, 13, 7, 5, 5, 20, 7, 7, 16, 8])\n list([5, 1, 6, 5, 1, 6, 5, 3, 5, 5, 8, 6, 5, 5, 3, 5, 8, 8, 6, 5, 6, 3, 5, 6, 1, 1, 5, 3, 1, 5, 5, 2, 2, 3, 5, 5, 8, 6])],[list([34, 56, 933, 11, 0, 46, 119, 48, 1931, 2690, 77, 627, 7943, 19, 15624, 55, 12, 320, 757, 2, 407, 33, 191, 893, 7, 40157, 2, 818, 33, 22, 173, 2755, 214, 118, 3])\n list([[83, 98, 101], [183, 7, 98], [98, 158, 56, 98, 0, 130, 166, 98, 158], [34, 120, 191, 98, 101], [34, 158, 15, 0, 182, 16, 26, 98, 0, 34, 112], [0], [27], [177, 158, 176, 16], [158, 168, 34, 0, 136, 38, 183], [183, 24, 98, 0, 34, 158, 115, 98], [29, 146], [158, 16, 26, 98, 0, 98, 121, 97], [158, 176, 16, 0, 34, 180, 183], [182, 154], [71, 16, 168, 98, 0, 34, 15, 164, 98, 101], [98, 158, 15], [130, 95, 34], [37, 73, 183, 0, 37, 15, 81, 98, 101], [144, 158, 143, 98, 101, 0, 71, 156], [0], [158, 154, 97], [182, 168, 98], [98, 101, 121, 97], [29, 141, 98, 0, 177, 158, 7, 98, 101], [183, 143, 121], [16, 130, 71], [0], [182, 79, 98, 101], [182, 168, 98], [98, 158, 50, 98, 101], [98, 62, 16], [98, 158, 166, 97, 0, 183, 176, 130], [0, 0, 0], [20], [0]])\n list([2, 1, 12, 20, 7, 8, 8, 12, 1, 5, 20, 7, 7, 1, 12, 11, 4, 7, 12, 8, 1, 12, 17, 7, 20, 9, 8, 1, 12, 13, 7, 5, 8, 8, 8])\n list([5, 6, 1, 3, 5, 6, 6, 1, 6, 2, 3, 5, 5, 6, 1, 6, 5, 5, 1, 6, 6, 1, 6, 5, 3, 5, 6, 6, 1, 5, 5, 2, 6, 6, 6])]\ny: ItemList\n[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 8, 3, 3],[3, 3, 3, 3, 6, 3],[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 3, 3, 3, 3, 6, 7, 7, 3, 6, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 8, 3],[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3]\nPath: .;\n\nValid: LabelList (2000 items)\nx: ItemList\n[list([17, 823, 1055, 19, 272, 56, 17, 137, 1055, 73, 45, 235, 651])\n list([[98, 101, 15, 171, 16], [183, 179, 130], [34, 158, 15], [182, 154], [183, 158, 168, 34], [183, 7, 98], [98, 101, 15, 171, 16], [98, 158, 115, 98], [34, 158, 15], [34, 158, 146], [71, 155], [71, 47, 34], [0]])\n list([2, 12, 7, 1, 12, 1, 7, 12, 7, 11, 12, 12, 8]) list([5, 1, 5, 6, 1, 6, 5, 1, 5, 6, 1, 1, 6])],[list([6335, 109, 156, 55, 156, 113, 38, 56, 1646, 23175, 33, 3121, 458, 1878, 3])\n list([[71, 16, 168, 34, 0, 71, 121, 191, 0, 98, 158, 16, 88, 69], [71, 137], [130, 3], [98, 158, 15], [130, 3], [182, 15, 171, 98, 101], [136, 13], [183, 7, 98], [182, 121, 69, 0, 144, 158, 116], [144, 158, 126, 183, 0, 34, 158, 121, 98], [182, 168, 98], [183, 166, 98], [18, 7, 98, 101], [98, 15, 164, 183, 0, 130, 47, 34], [0]])\n list([13, 2, 7, 11, 7, 16, 1, 12, 5, 12, 20, 12, 7, 7, 8]) list([5, 5, 5, 6, 5, 5, 6, 1, 2, 1, 3, 1, 5, 5, 6])],[list([7015, 100, 75, 938, 223, 2, 156, 75, 39, 38, 55, 109, 156, 132, 618, 2, 39, 38, 8, 12, 109, 156, 542, 776, 18428, 77, 68, 24, 139, 3893, 10358, 77, 68, 75, 19, 938, 223, 173, 3363, 11112, 3])\n list([[83, 16], [98, 168, 69], [130, 146, 98, 158], [98, 101, 154], [117, 69, 156, 98, 101], [0], [130, 3], [130, 146, 98, 158], [183, 167, 98, 101], [136, 13], [98, 158, 15], [71, 137], [130, 3], [56, 97], [34, 158, 83, 16], [0], [183, 167, 98, 101], [136, 13], [37, 137], [130, 95, 34], [71, 137], [130, 3], [136, 69, 156, 34], [182, 171, 16], [158, 16, 0, 136, 16, 98, 158], [29, 146], [183, 191, 98], [182, 76], [120, 8, 16], [130, 154, 16, 0, 130, 154, 16], [182, 121, 69, 0, 117, 126, 34], [29, 146], [183, 191, 98], [130, 146, 98, 158], [182, 154], [98, 101, 154], [117, 69, 156, 98, 101], [98, 62, 16], [183, 158, 16, 168, 98, 0, 34, 120, 15, 171, 98, 101], [144, 158, 126, 16, 0, 37, 112, 121], [0]])\n list([14, 11, 15, 12, 12, 8, 7, 15, 1, 1, 11, 2, 7, 15, 17, 8, 1, 1, 12, 4, 2, 7, 5, 7, 12, 20, 7, 20, 11, 1, 5, 20, 7, 15, 1, 12, 12, 7, 7, 7, 8])\n list([6, 6, 5, 1, 1, 6, 5, 5, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 1, 5, 5, 5, 2, 5, 1, 3, 5, 3, 6, 6, 2, 3, 5, 5, 6, 1, 1, 5, 5, 5, 6])],[list([156, 2788, 651]) list([[130, 3], [62, 16], [0]]) list([7, 14, 8]) list([5, 6, 6])],[list([68, 59, 61, 354, 21, 544, 68, 1098, 156, 785, 831, 142, 69, 39, 2642, 418, 156, 31, 58, 3])\n list([[183, 191, 98], [71, 16, 168, 34], [98, 126, 16], [136, 121, 191], [144, 158, 16], [37, 7, 98, 101], [183, 191, 98], [34, 158, 15, 62, 98, 101], [130, 3], [34, 120, 141, 130], [98, 101, 158, 146, 98], [34, 120, 16, 26, 69], [130, 137], [183, 167, 98, 101], [182, 137, 98, 158], [117, 121], [130, 3], [120, 121], [182, 16], [0]])\n list([7, 12, 12, 15, 7, 7, 7, 12, 7, 4, 4, 4, 11, 1, 12, 12, 7, 12, 12, 8])\n list([5, 1, 1, 5, 5, 5, 5, 1, 5, 5, 5, 5, 6, 6, 1, 1, 5, 1, 1, 6])]\ny: ItemList\n[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 3],[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\nPath: .;\n\nTest: LabelList (2831 items)\nx: ItemList\n[list([124, 939, 1555, 423, 568, 80, 51, 49, 86, 3500, 91, 8262, 89, 135, 202, 14214, 21, 275, 50, 13, 123, 381, 27, 206, 272, 7, 152, 3])\n list([[183, 158, 155], [130, 16, 98, 158], [83, 130], [182, 38, 121], [183, 191, 98, 0, 101, 86, 16], [130, 164, 16], [158, 62, 98], [158, 121, 16], [34, 158, 86, 98, 101], [120, 15, 11, 16], [34, 69, 116, 16], [98, 56, 183], [37, 88, 98], [34, 79, 98, 101], [34, 16, 168, 98, 101], [34, 158, 176, 130, 0, 34, 158, 16, 168, 34], [144, 158, 16], [144, 76], [37, 166, 16], [183, 158, 191], [183, 158, 42, 98, 101, 0, 34, 83, 16], [98, 101, 158, 65], [29, 133], [183, 86, 16], [183, 158, 168, 34], [183, 143, 121], [183, 158, 8, 98, 101], [0]])\n list([2, 16, 12, 2, 7, 1, 5, 4, 7, 4, 7, 12, 12, 1, 7, 5, 7, 12, 12, 20, 15, 12, 20, 2, 12, 20, 7, 8])\n list([5, 5, 1, 5, 5, 6, 2, 5, 5, 5, 5, 1, 1, 6, 5, 2, 5, 1, 1, 3, 5, 1, 3, 5, 1, 3, 5, 6])],[list([40, 529, 774, 26103, 1909, 2, 22, 3216, 1878, 9259, 2126, 2034, 42, 2610, 17, 27960, 256, 2, 135, 3216, 4162, 34768, 259, 223, 17, 423, 291, 56, 26120, 124, 63, 1555, 60, 2343, 214])\n list([[34, 79], [182, 83, 16], [130, 47, 34], [34, 158, 72, 130, 0, 49, 69, 179, 98, 101], [130, 26, 34, 0, 130, 189, 16], [0], [98, 158, 50, 98, 101], [101, 16, 9, 34], [98, 15, 164, 183, 0, 130, 47, 34], [98, 156, 16, 0, 34, 16, 168, 177], [183, 158, 176, 97], [34, 120, 137, 98], [34, 120, 88, 98], [144, 158, 69, 83, 98, 0, 130, 180, 34], [98, 101, 15, 171, 16], [49, 69, 176, 0, 177, 158, 12], [34, 120, 134], [0], [34, 79, 98, 101], [101, 16, 9, 34], [37, 26], [130, 180, 98, 0, 183, 158, 86, 34], [98, 158, 189], [117, 69, 156, 98, 101], [98, 101, 15, 171, 16], [182, 38, 121], [71, 64], [183, 7, 98], [182, 189, 0, 158, 189, 98], [183, 158, 155], [182, 121, 98, 101], [83, 130], [34, 120, 15, 164, 183], [98, 101, 73, 183], [0, 0, 0]])\n list([20, 4, 7, 5, 5, 8, 13, 7, 7, 12, 12, 12, 20, 7, 2, 7, 5, 8, 1, 7, 7, 5, 12, 12, 7, 2, 7, 1, 5, 2, 1, 12, 20, 7, 8])\n list([3, 5, 5, 2, 2, 6, 5, 5, 5, 1, 1, 1, 3, 5, 5, 5, 2, 6, 6, 5, 5, 2, 1, 1, 5, 5, 5, 6, 2, 5, 6, 1, 3, 5, 6])],[list([16, 62, 1878, 2, 4740, 6, 1023, 7, 15, 4378, 840, 42, 1752, 174, 2, 70, 19, 48, 3526, 13, 103, 119, 854, 1577, 118, 111, 203, 3049, 7, 75, 3])\n list([[144, 158, 83, 98, 101], [183, 158, 32], [98, 15, 164, 183, 0, 130, 47, 34], [0], [130, 8, 0, 158, 83, 16], [29, 137], [130, 86, 69], [183, 143, 121], [183, 86, 183], [34, 158, 69, 97, 133, 98, 0, 29, 16, 88, 98], [182, 116], [34, 120, 88, 98], [136, 137, 98], [34, 137, 69], [0], [158, 9], [182, 154], [177, 158, 176, 16], [34, 120, 176, 0, 101, 16, 86], [183, 158, 191], [183, 69, 95, 183], [27], [34, 158, 191, 86, 34], [98, 101, 158, 85, 191], [20], [71, 43, 98, 101], [183, 158, 44, 98, 158], [34, 44, 98, 158, 0, 130, 166, 98, 101], [183, 143, 121], [130, 146, 98, 158], [0]])\n list([1, 1, 7, 8, 7, 11, 7, 20, 13, 7, 12, 20, 7, 7, 8, 15, 1, 12, 12, 20, 7, 8, 12, 5, 8, 20, 17, 7, 20, 15, 8])\n list([6, 6, 5, 6, 5, 6, 5, 3, 5, 5, 1, 3, 5, 5, 6, 5, 6, 1, 1, 3, 5, 6, 1, 2, 6, 3, 6, 5, 3, 5, 6])],[list([62, 406, 388, 50328, 35, 1985, 36, 19, 10, 0, 4378, 8261, 148, 35172, 11814, 3])\n list([[183, 158, 32], [120, 16, 88, 98, 101], [117, 154], [183, 15, 62, 98, 101, 0, 101, 16, 86, 98], [0], [158, 137, 0, 34, 66, 98, 158], [0], [182, 154], [183, 126], [0, 0], [34, 158, 69, 97, 133, 98, 0, 29, 16, 88, 98], [34, 112, 0, 98, 166, 98], [101, 16, 50, 121], [34, 120, 78, 98, 101, 0, 18, 15, 62, 98, 101], [71, 121, 191, 0, 37, 121], [0]])\n list([1, 5, 7, 16, 8, 16, 8, 1, 12, 4, 7, 12, 20, 7, 5, 8]) list([6, 2, 5, 8, 6, 5, 6, 6, 1, 5, 5, 1, 3, 5, 2, 6])],[list([20, 0, 35, 1569, 36, 39, 10, 22, 4378, 23987, 173, 207, 2324, 4944, 214])\n list([[127], [98, 101, 158, 16, 0, 158, 176, 16], [0], [98, 101, 158, 26, 0, 121, 98], [0], [183, 167, 98, 101], [183, 126], [98, 158, 50, 98, 101], [34, 158, 69, 97, 133, 98, 0, 29, 16, 88, 98], [71, 189, 0, 117, 86, 183], [98, 62, 16], [71, 16, 76, 98], [144, 158, 62, 16], [117, 121, 0, 117, 83, 16], [0, 0, 0]])\n list([20, 16, 8, 16, 8, 1, 12, 13, 7, 12, 7, 7, 7, 5, 8]) list([3, 5, 6, 5, 6, 6, 1, 5, 5, 1, 5, 5, 5, 2, 6])]\ny: ItemList\n[3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 3, 4, 8, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],[3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\nPath: ., model=BiLstmCrf(\n  (context_lstm): ContextLSTM(\n    (chunk_embedding): Embedding(9, 8, padding_idx=0)\n    (pos_embedding): Embedding(21, 20, padding_idx=0)\n    (word_embedding): Embedding(107772, 300, padding_idx=1)\n    (character_lstm): CharacterLSTM(\n      (embedding): Embedding(199, 100, padding_idx=1)\n      (lstm): LSTM(100, 100, bidirectional=True)\n    )\n    (context_lstm): LSTM(528, 150, bidirectional=True)\n  )\n  (hidden2tag): Linear(in_features=300, out_features=9, bias=True)\n  (crf): CRF(num_tags=9)\n), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<function BiLstmCrf.get_loss_func.<locals>.loss_func at 0x7f61d8bf4d08>, metrics=[], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n  (0): Embedding(9, 8, padding_idx=0)\n  (1): Embedding(21, 20, padding_idx=0)\n  (2): Embedding(107772, 300, padding_idx=1)\n  (3): Embedding(199, 100, padding_idx=1)\n  (4): LSTM(100, 100, bidirectional=True)\n  (5): LSTM(528, 150, bidirectional=True)\n  (6): Linear(in_features=300, out_features=9, bias=True)\n  (7): CRF(num_tags=9)\n)], add_time=True, silent=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 38
    }
   ],
   "source": [
    "learner.load('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='354', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[0.023971697, 86.6779089376054, 85.78104138851802, 86.22714309679584]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 39
    }
   ],
   "source": [
    "learner.validate(dl=learner.data.test_dl, callbacks=[conlleval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}